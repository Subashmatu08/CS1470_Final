This is a reimplementation of the paper "Detecting Deepfakes Without Seeing Any." Deepfake detectors for audio-visual and face swapping scenarios were implemented.

## INSTALLATION

Create a virtual conda environment, activate it, and install the requirements file. You must also install faiss-cpu or faiss-gpu and sentencepiece and dlib, both of which first require cmake.

## FACTOR, AV-HuBERT and FaceX-Zoo

This implementation is based off of FACTOR, AV-HuBERT, and FaceX-Zoo; please refer to the original [AV-HuBERT](https://github.com/facebookresearch/av_hubert.git), [FaceX-Zoo](https://github.com/JDAI-CV/FaceX-Zoo.git), and [FACTOR](https://github.com/talreiss/FACTOR.git) repositories. 
